{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from tensorflow.keras.layers import Conv2D,Activation, MaxPool2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1916 files [00:04, 396.01 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio((r\"C:\\Users\\Shalaka-Deshpande\\Downloads\\Handgestures1\\Hand\"), output=\"output\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3384 images belonging to 8 classes.\n",
      "Found 416 images belonging to 8 classes.\n",
      "Found 432 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "import tensorflow.keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=0)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'output/train',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        'output/val',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        'output/test',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_head(input_shape):\n",
    "\n",
    "  model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape= input_shape))\n",
    "  model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "  model.add(Conv2D(filters = 32, kernel_size = (3,3)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Conv2D(filters = 64, kernel_size = (3,3)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "def model_tail(input_shape = (16,)):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(256, activation='relu',input_shape=input_shape))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio((r\"C:\\Users\\Shalaka-Deshpande\\Downloads\\Handgestures1\\Masks\"), output=\"output1\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow.keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=0)\n",
    "train_generator1 = train_datagen.flow_from_directory(\n",
    "        'output1/train',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator1 = train_datagen.flow_from_directory(\n",
    "        'output1/val',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "test_generator1 = train_datagen.flow_from_directory(\n",
    "        'output1/test',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 248, 248, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 246, 246, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 246, 246, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 121, 121, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 121, 121, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 230400)            0         \n",
      "=================================================================\n",
      "Total params: 28,640\n",
      "Trainable params: 28,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "head = model_head((250, 250, 3))\n",
    "tail = model_tail()\n",
    "\n",
    "model = models.Model([head, tail])\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-4beb9962badb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"uhfuhe.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anacondapython\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \"\"\"\n\u001b[0;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1008\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anacondapython\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    103\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[0;32m    104\u001b[0m       raise NotImplementedError(\n\u001b[1;32m--> 105\u001b[1;33m           \u001b[1;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m           \u001b[1;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m           \u001b[1;34m'subclassed models, because such models are defined via the body of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "model.save(\"uhfuhe.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"modelHand.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-1a3448913add>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anacondapython\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \"\"\"\n\u001b[1;32m-> 1254\u001b[1;33m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m     return json.dumps(\n\u001b[0;32m   1256\u001b[0m         model_config, default=serialization.get_json_type, **kwargs)\n",
      "\u001b[1;32m~\\Anacondapython\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_updated_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m     model_config = {\n\u001b[0;32m   1234\u001b[0m         \u001b[1;34m'class_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anacondapython\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    915\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "    \n",
    "#serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(r\"C:\\Users\\Shalaka-Deshpande\\Downloads\\Handgestures1\\Maskmodel\", save_format='tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/51806852/cant-save-custom-subclassed-model#:~:text=In%20Saving%20Subclassed%20Models%20section,be%20safely%20serialized%20and%20deserialized.&text=This%20means%20that%20the%20architecture%20of%20the%20model%20cannot%20be%20safely%20serialized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
